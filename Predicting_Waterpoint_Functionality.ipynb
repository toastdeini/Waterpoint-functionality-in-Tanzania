{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Functionality of Waterpoints in Tanzania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/lake_victoria.jpg)\n",
    "\n",
    "Lake Victoria in Tanzania - photo courtesy of [thepinkbackpack.com](https://www.thepinkbackpack.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 4 million of Tanzania's 59 million residents lack access to potable (drinking) water; an even greater proportion of the Tanzanian population (nearly half) lack access to what water.org calls \"[improved sanitation](https://water.org/our-impact/where-we-work/tanzania/)\".\n",
    "\n",
    "While the majority of Tanzanians *do* have access to clean water, a quick look at the functionality status of about 60,000 waterpoints (wells, pumps, etc.) indicates that nearly **half** of those waterpoints either need repair to function consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/target_val_counts.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data used in this classification project comes from an ongoing competition hosted by DrivenData, [*Pump it Up: Data Mining the Water Table*](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
    "\n",
    "\n",
    "\n",
    "Repository structure for running this notebook available at the bottom of the [README.md](https://github.com/toastdeini/dsc-ph3-Tanzanian-water-well-status/blob/main/README.md).\n",
    "\n",
    "Descriptions of each column can be found at [this link](data_dict_basic.txt) within this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loadout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:40:02.747776Z",
     "start_time": "2022-04-22T15:40:02.733980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Packages for data cleaning, plotting, and manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning libraries/functions/classes\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "                            classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "                             StackingClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:24.924933Z",
     "start_time": "2022-04-22T15:23:23.300459Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing training data\n",
    "train_val = pd.read_csv('data/training_set_values.csv')\n",
    "\n",
    "# Only using `status_group` column from label set, to\n",
    "# avoid duplicating `id` column\n",
    "train_label = pd.read_csv('data/training_set_labels.csv',\n",
    "                             usecols = ['status_group'])\n",
    "\n",
    "\n",
    "# Test set, provided by DrivenData - not to be used\n",
    "# until models have been trained, internally validated, etc.\n",
    "\n",
    "test_df = pd.read_csv('data/test_set_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:25.327626Z",
     "start_time": "2022-04-22T15:23:25.240494Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenating separate .csv files\n",
    "df = pd.concat(objs = [train_val, train_label],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:26.239062Z",
     "start_time": "2022-04-22T15:23:25.998016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27487</th>\n",
       "      <td>60684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>Dwe</td>\n",
       "      <td>1137</td>\n",
       "      <td>DWE</td>\n",
       "      <td>37.136702</td>\n",
       "      <td>-4.075092</td>\n",
       "      <td>Madukani</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52964</th>\n",
       "      <td>457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.368774</td>\n",
       "      <td>-8.767996</td>\n",
       "      <td>Kwa Mzee Lusambo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26478</th>\n",
       "      <td>7855</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2011-03-24</td>\n",
       "      <td>Private Individual</td>\n",
       "      <td>-8</td>\n",
       "      <td>Da</td>\n",
       "      <td>38.991011</td>\n",
       "      <td>-6.537616</td>\n",
       "      <td>Bakari</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59113</th>\n",
       "      <td>50299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>1068</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.806314</td>\n",
       "      <td>-3.448869</td>\n",
       "      <td>Kwa Elishirikiamwea Swai</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14153</th>\n",
       "      <td>70382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>He</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "      <td>31.635313</td>\n",
       "      <td>-1.718094</td>\n",
       "      <td>Kabubuya</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "27487  60684         0.0    2013-02-15                     Dwe        1137   \n",
       "52964    457         0.0    2011-04-06                     NaN           0   \n",
       "26478   7855        50.0    2011-03-24      Private Individual          -8   \n",
       "59113  50299         0.0    2013-03-19  Government Of Tanzania        1068   \n",
       "14153  70382         0.0    2011-07-27                      He           0   \n",
       "\n",
       "      installer  longitude  latitude                  wpt_name  num_private  \\\n",
       "27487       DWE  37.136702 -4.075092                  Madukani            0   \n",
       "52964       NaN  34.368774 -8.767996          Kwa Mzee Lusambo            0   \n",
       "26478        Da  38.991011 -6.537616                    Bakari            0   \n",
       "59113       DWE  36.806314 -3.448869  Kwa Elishirikiamwea Swai            0   \n",
       "14153        HE  31.635313 -1.718094                  Kabubuya            0   \n",
       "\n",
       "       ... water_quality quality_group  quantity  quantity_group  source  \\\n",
       "27487  ...          soft          good    enough          enough  spring   \n",
       "52964  ...          soft          good  seasonal        seasonal   river   \n",
       "26478  ...          soft          good    enough          enough   river   \n",
       "59113  ...          soft          good    enough          enough  spring   \n",
       "14153  ...          soft          good    enough          enough  spring   \n",
       "\n",
       "      source_type source_class     waterpoint_type waterpoint_type_group  \\\n",
       "27487      spring  groundwater  communal standpipe    communal standpipe   \n",
       "52964  river/lake      surface  communal standpipe    communal standpipe   \n",
       "26478  river/lake      surface  communal standpipe    communal standpipe   \n",
       "59113      spring  groundwater               other                 other   \n",
       "14153      spring  groundwater           hand pump             hand pump   \n",
       "\n",
       "         status_group  \n",
       "27487  non functional  \n",
       "52964  non functional  \n",
       "26478      functional  \n",
       "59113      functional  \n",
       "14153  non functional  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick readout\n",
    "df.sample(n = 5,\n",
    "          random_state = 138)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Comprehension and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:26.977884Z",
     "start_time": "2022-04-22T15:23:26.722811Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about **forty** potential features here, indicated by columns `0` through `39`; column `40`, `status_group`, is our target variable. The majority (30) of those columns are currently stored as type `object`, the remainder as either `int64` or `float64`.\n",
    "\n",
    "Thorough exploratory analysis revealed that a number of these columns contained information that was redundant with other columns, not informative to the modeling process, or otherwise superfluous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:27.531287Z",
     "start_time": "2022-04-22T15:23:27.521501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns determined to be either irrelevant or\n",
    "# superfluous in exploratory analysis\n",
    "\n",
    "cols_to_drop = [\n",
    "    'id',  # unique identifier, not useful for modeling\n",
    "    'date_recorded',  # superfluous information, too many unique records\n",
    "    'recorded_by',  # no unique information + no unique values across 59.4k rows\n",
    "    'funder',   \n",
    "    'installer',  # large number of unique values (see also `funder`);\n",
    "                  # may be added back in later\n",
    "    'wpt_name',  # identifier column, not useful for modeling\n",
    "    'num_private',  # data dict. does not provide details for this column\n",
    "    'subvillage',  # too many unique values - uninformative for modeling\n",
    "    'region_code',  # redundant information vis-a-visa the simpler `region`\n",
    "    'district_code',  # may be added back in later\n",
    "    'lga',\n",
    "    'ward',  # redundant location data (with `lga`)\n",
    "    'scheme_management',  # may be added back in later\n",
    "    'scheme_name',  # large number of nulls, redundant vis-a-vis `scheme_management`\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',  # using `extraction_type_class` for generalized info\n",
    "    'management',\n",
    "    'management_group',  # may be added back in later\n",
    "    'payment',  # identical information to `payment_type`\n",
    "    'water_quality',  # comparable information to `quality_group` - redundant\n",
    "    'quantity_group',  # identical information to `quantity` - redundant\n",
    "    'source',  # redundant with other `source_` columns\n",
    "    'waterpoint_type'  # used `waterpoint_type_group` instead\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:28.074187Z",
     "start_time": "2022-04-22T15:23:28.018571Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = cols_to_drop).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our data leakage is kept to a minimum - ideally zero - I first set up pipelines to impute missing or null values, one-hot encode categorical variables, and scale numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:28.536830Z",
     "start_time": "2022-04-22T15:23:28.510598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subpipes for imputing median values - to be used for `latitude` and `longitude`\n",
    "subpipe_lat      = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = -2.000000e-08,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "subpipe_long     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0.000000,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "\n",
    "# Subpipe for imputing median values\n",
    "subpipe_num      = Pipeline(steps=[('num_impute', SimpleImputer(strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for `construction_year`\n",
    "subpipe_year     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for categorical features including `basin`, `payment_type`\n",
    "subpipe_cat      = Pipeline(steps=[('freq_imputer_nan', SimpleImputer(strategy = 'most_frequent')),\n",
    "                                   ('freq_imputer_unk', SimpleImputer(strategy = 'most_frequent',\n",
    "                                                                      missing_values = 'unknown')),\n",
    "                                   ('ohe', OneHotEncoder(drop = 'if_binary',\n",
    "                                                         sparse = False,\n",
    "                                                         handle_unknown = 'ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:29.243019Z",
     "start_time": "2022-04-22T15:23:29.226063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to be passed through numerical pipeline\n",
    "num_cols = ['amount_tsh',\n",
    "            'gps_height',\n",
    "            'population']\n",
    "\n",
    "# Columns to be passed through categorical pipeline\n",
    "cat_cols = ['basin',\n",
    "            'region',\n",
    "            'payment_type',\n",
    "            'quantity',\n",
    "            'quality_group',\n",
    "            'permit',\n",
    "            'public_meeting',\n",
    "            'extraction_type_class',\n",
    "            'source_type',\n",
    "            'source_class',\n",
    "            'waterpoint_type_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:29.673248Z",
     "start_time": "2022-04-22T15:23:29.663350Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num', subpipe_num, num_cols),\n",
    "    ('subpipe_year', subpipe_year, ['construction_year']),\n",
    "    ('subpipe_long', subpipe_long, ['longitude']),\n",
    "    ('subpipe_lat', subpipe_lat, ['latitude']),\n",
    "    ('subpipe_cat', subpipe_cat, cat_cols)],\n",
    "                       remainder = 'passthrough')\n",
    "\n",
    "# ('subpipe_label', subpipe_label, ['status_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:30.332122Z",
     "start_time": "2022-04-22T15:23:30.278109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting DataFrame into features/values DataFrame\n",
    "# (i.e. `X`) and labels series (`y`)\n",
    "\n",
    "X = df.drop('status_group', axis = 1)\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:31.043873Z",
     "start_time": "2022-04-22T15:23:30.993207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting internal training data into separate\n",
    "# training and test sets for (eventual) internal validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 138)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, I start with a baseline model - sklearn's `DummyClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:31.897446Z",
     "start_time": "2022-04-22T15:23:31.889152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline for dummy model\n",
    "dummy_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('dummy', DummyClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:35.223194Z",
     "start_time": "2022-04-22T15:23:33.321462Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420875420875421"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "dummy_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Score on training data\n",
    "dummy_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn's `DummyClassifier` predicts on the training data with an accuracy score of ~0.542, equal to the proportion of the **most frequent class** (`functional`). This is because, as a dummy model, it predicts `functional` (the most frequent value) every time.\n",
    "\n",
    "We'll be looking to improve on that 54.2% accuracy in future models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The full, verbose modeling process is available to view in [this notebook](Jupyter_Notebooks/Modeling_Scratchwork.ipynb) within the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is an ensemble model - it combines a `RandomForestClassifier` and an `XGBClassifier`, using sklearn's `StackingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:36.390784Z",
     "start_time": "2022-04-22T15:23:36.378797Z"
    }
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier pipeline\n",
    "rfc_pipe_three = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_features = 'sqrt',\n",
    "                                   max_depth = 15,\n",
    "                                   random_state = 138))\n",
    "])\n",
    "\n",
    "\n",
    "# XGBoost classifier pipeline\n",
    "xgb_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('xgb', XGBClassifier(random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:23:38.822862Z",
     "start_time": "2022-04-22T15:23:38.803525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up estimators for StackingClassifier\n",
    "final_estimators = [\n",
    "    ('rfc_model', rfc_pipe_three),\n",
    "    ('xgb_model', xgb_model_pipe)\n",
    "]\n",
    "\n",
    "final_model_pipe = StackingClassifier(final_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:26:22.284766Z",
     "start_time": "2022-04-22T15:23:44.867230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rfc_model',\n",
       "                                Pipeline(steps=[('ct',\n",
       "                                                 ColumnTransformer(remainder='passthrough',\n",
       "                                                                   transformers=[('subpipe_num',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                                                  ('ss',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  ['amount_tsh',\n",
       "                                                                                   'gps_height',\n",
       "                                                                                   'population']),\n",
       "                                                                                 ('subpipe_year',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(missing_values=0,\n",
       "                                                                                                                 stra...\n",
       "                                                               importance_type='gain',\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=138,\n",
       "                                                               reg_alpha=None,\n",
       "                                                               reg_lambda=None,\n",
       "                                                               scale_pos_weight=None,\n",
       "                                                               subsample=None,\n",
       "                                                               tree_method=None,\n",
       "                                                               validate_parameters=None,\n",
       "                                                               verbosity=None))]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:26:30.418887Z",
     "start_time": "2022-04-22T15:26:27.095335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507965224383135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:39:22.898450Z",
     "start_time": "2022-04-22T15:26:34.900341Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79020101, 0.78592965, 0.78756281, 0.78464631, 0.79469783])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator = final_model_pipe,\n",
    "                X = X_train,\n",
    "                y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower scores on cross-validation *vis-a-vis* the simple accuracy score on the training data indicate that this model is likely overfit. Future models will need further hyperparametric tuning and more thorough analysis to reduce that overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:40:14.113281Z",
     "start_time": "2022-04-22T15:40:08.184307Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.95      0.88     21574\n",
      "functional needs repair       0.85      0.36      0.51      2921\n",
      "         non functional       0.90      0.81      0.85     15303\n",
      "\n",
      "               accuracy                           0.85     39798\n",
      "              macro avg       0.86      0.71      0.75     39798\n",
      "           weighted avg       0.86      0.85      0.84     39798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_train,\n",
    "                            y_pred = final_model_pipe.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the training data, we got an overall accuracy of about `0.85`. The `f1-score` column provides a more detailed analysis into the combined `precision` and `recall` scores for our model's prediction on the target classes. `functional` and `non functional` have F1 scores in the 0.8 - 0.9 range, whereas  the `functional needs repair` class has a considerably lower F1 score, 0.51 - our model was *less* effective in predicting this class.\n",
    "\n",
    "Considering that cross-validation showed our model to be likely overfit, we can anticipate these scores dropping somewhat when unseen data is used inplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:41:49.609306Z",
     "start_time": "2022-04-22T15:41:47.643815Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909907152331395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T15:41:56.408126Z",
     "start_time": "2022-04-22T15:41:53.812214Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.77      0.91      0.83     10685\n",
      "functional needs repair       0.62      0.22      0.33      1396\n",
      "         non functional       0.84      0.73      0.78      7521\n",
      "\n",
      "               accuracy                           0.79     19602\n",
      "              macro avg       0.74      0.62      0.65     19602\n",
      "           weighted avg       0.79      0.79      0.78     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test,\n",
    "                            y_pred = final_model_pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Accuracy score:*** 0.79\n",
    "- ***Precision score* for `non functional` predictions**: 0.84\n",
    "- **Final `f1-score` per status group** (on test data):\n",
    "    - `functional` - 0.83\n",
    "    - `functional needs repair` - 0.33\n",
    "    - `non functional` - 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T16:38:11.608801Z",
     "start_time": "2022-04-22T16:38:11.314510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rfc_model',\n",
       "                                Pipeline(steps=[('ct',\n",
       "                                                 ColumnTransformer(remainder='passthrough',\n",
       "                                                                   transformers=[('subpipe_num',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                                                  ('ss',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  ['amount_tsh',\n",
       "                                                                                   'gps_height',\n",
       "                                                                                   'population']),\n",
       "                                                                                 ('subpipe_year',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(missing_values=0,\n",
       "                                                                                                                 stra...\n",
       "                                                               importance_type='gain',\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=138,\n",
       "                                                               reg_alpha=None,\n",
       "                                                               reg_lambda=None,\n",
       "                                                               scale_pos_weight=None,\n",
       "                                                               subsample=None,\n",
       "                                                               tree_method=None,\n",
       "                                                               validate_parameters=None,\n",
       "                                                               verbosity=None))]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model's accuracy on unseen data was `0.7909`, or just under **80%**. This score represents the proportion of correct predictions, i.e. instances where our model correctly guessed a well's functionality status.\n",
    "\n",
    "With regards to `non functional` wells, specifically, our model attained a **precision score** of about **0.84** - intuitively, this means that 84% of waterpoints identified by the model as `non functional` were *true positives*, i.e. wells that were truly non-functional.\n",
    "\n",
    "The **F1 scores** provide us with harmonic means of the model's precision and recall scores for each target class; respectively, the descending F1 scores of 0.83 for the `functional` class, 0.78 for the `non functional` class, and 0.33 for the `functional needs repair` class. While the F1 scores for the functional and non-functional classes are comparable to the overall accuracy, the F1 score for predicting wells that are functional but need repair is considerably lower - the model is not predicting on this class of waterpoints with as much success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References/Other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
