{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Scratchwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:17:17.224801Z",
     "start_time": "2022-04-21T15:17:17.194778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Packages for data cleaning, plotting, and manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# scikit-learn libraries/functions/classes\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "                             StackingClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:30.378619Z",
     "start_time": "2022-04-21T14:06:30.365308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shows *all* columns in dataframe, i.e. does not truncate horizontally;\n",
    "# feel free to comment out if undesired\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:30.788255Z",
     "start_time": "2022-04-21T14:06:30.411797Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing training data\n",
    "train_val = pd.read_csv('../data/training_set_values.csv')\n",
    "\n",
    "# Only using `status_group` column from label set, to\n",
    "# avoid duplicating `id` column\n",
    "train_label = pd.read_csv('../data/training_set_labels.csv',\n",
    "                             usecols = ['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:30.927662Z",
     "start_time": "2022-04-21T14:06:30.882335Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenating separate .csv files\n",
    "df = pd.concat(objs = [train_val, train_label],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:31.071192Z",
     "start_time": "2022-04-21T14:06:31.062062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns determined to be either irrelevant or\n",
    "# superfluous in exploratory analysis\n",
    "\n",
    "cols_to_drop = [\n",
    "    'id',  # unique identifier, not useful for modeling\n",
    "    'date_recorded',  # superfluous information, too many unique records\n",
    "    'recorded_by',  # no unique information + no unique values across 59.4k rows\n",
    "    'funder',   \n",
    "    'installer',  # large number of unique values (see also `funder`);\n",
    "                  # may be added back in later\n",
    "    'wpt_name',  # identifier column, not useful for modeling\n",
    "    'num_private',  # data dict. does not provide details for this column\n",
    "    'subvillage',  # too many unique values - uninformative for modeling\n",
    "    'region_code',  # redundant information vis-a-visa the simpler `region`\n",
    "    'district_code',  # may be added back in later\n",
    "    'lga',\n",
    "    'ward',  # redundant location data (with `lga`)\n",
    "    'scheme_management',  # may be added back in later\n",
    "    'scheme_name',  # large number of nulls, redundant vis-a-vis `scheme_management`\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',  # using `extraction_type_class` for generalized info\n",
    "    'management',\n",
    "    'management_group',  # may be added back in later\n",
    "    'payment',  # identical information to `payment_type`\n",
    "    'water_quality',  # comparable information to `quality_group` - redundant\n",
    "    'quantity_group',  # identical information to `quantity` - redundant\n",
    "    'source',  # redundant with other `source_` columns\n",
    "    'waterpoint_type'  # used `waterpoint_type_group` instead\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:31.241378Z",
     "start_time": "2022-04-21T14:06:31.196101Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = cols_to_drop).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary modifications for modeling, to be written into pipelines:\n",
    "\n",
    "- One-hot encoding:\n",
    "    - `basin`\n",
    "    - `extraction_type_class`\n",
    "    - `payment_type`\n",
    "    - `permit`\n",
    "    - `public_meeting`\n",
    "    - `quality_group`\n",
    "    - `quantity`\n",
    "    - `region`\n",
    "    - `source_type`\n",
    "    - `source_class`\n",
    "    - `waterpoint_type_group`\n",
    "- Numerical scaling:\n",
    "    - `population` - (impute zeroes with median?)\n",
    "    - `gps_height` - impute zeroes with median\n",
    "    - `latitude` / `longitude` - impute zeroes with mean\n",
    "    - `construction_year` - use KNN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:32.454627Z",
     "start_time": "2022-04-21T14:06:32.439677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subpipes for imputing median values - to be used for `latitude` and `longitude`\n",
    "subpipe_lat      = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = -2.000000e-08,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "subpipe_long     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0.000000,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "\n",
    "# Subpipe for imputing median values\n",
    "subpipe_num      = Pipeline(steps=[('num_impute', SimpleImputer(strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for `construction_year`\n",
    "subpipe_year     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for categorical features including `basin`, `payment_type`\n",
    "subpipe_cat      = Pipeline(steps=[('freq_imputer_nan', SimpleImputer(strategy = 'most_frequent')),\n",
    "                                   ('freq_imputer_unk', SimpleImputer(strategy = 'most_frequent',\n",
    "                                                                      missing_values = 'unknown')),\n",
    "                                   ('ohe', OneHotEncoder(drop = 'if_binary',\n",
    "                                                         sparse = False,\n",
    "                                                         handle_unknown = 'ignore'))])\n",
    "\n",
    "\n",
    "# Subpipe for the target column, `status_group`\n",
    "subpipe_label    = Pipeline(steps=[('le', LabelEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:32.919369Z",
     "start_time": "2022-04-21T14:06:32.911392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to be passed through numerical pipeline\n",
    "num_cols = ['amount_tsh',\n",
    "            'gps_height',\n",
    "            'population']\n",
    "\n",
    "# Columns to be passed through categorical pipeline\n",
    "cat_cols = ['basin',\n",
    "            'region',\n",
    "            'payment_type',\n",
    "            'quantity',\n",
    "            'quality_group',\n",
    "            'permit',\n",
    "            'public_meeting',\n",
    "            'extraction_type_class',\n",
    "            'source_type',\n",
    "            'source_class',\n",
    "            'waterpoint_type_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:33.687174Z",
     "start_time": "2022-04-21T14:06:33.670045Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num', subpipe_num, num_cols),\n",
    "    ('subpipe_year', subpipe_year, ['construction_year']),\n",
    "    ('subpipe_long', subpipe_long, ['longitude']),\n",
    "    ('subpipe_lat', subpipe_lat, ['latitude']),\n",
    "    ('subpipe_cat', subpipe_cat, cat_cols)],\n",
    "                       remainder = 'passthrough')\n",
    "\n",
    "# ('subpipe_label', subpipe_label, ['status_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split and Initial Preparation for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:34.557236Z",
     "start_time": "2022-04-21T14:06:34.540266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting DataFrame into features/values DataFrame\n",
    "# (i.e. `X`) and labels series (`y`)\n",
    "\n",
    "X = df.drop('status_group', axis = 1)\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:06:34.998143Z",
     "start_time": "2022-04-21T14:06:34.962105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting internal training data into separate\n",
    "# training and test sets for (eventual) internal validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 138)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:31:30.277524Z",
     "start_time": "2022-04-21T15:31:30.270145Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('dummy', DummyClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:31:34.366738Z",
     "start_time": "2022-04-21T15:31:33.712798Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420875420875421"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "dummy_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Score on training data\n",
    "dummy_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn's `DummyClassifier` predicts on the training data with an accuracy score of ~0.542, equal to the proportion of the **most frequent class** (`functional`). This is because, as a dummy model, it predicts `functional` (the most frequent value) every time.\n",
    "\n",
    "We'll be looking to improve on that 54.2% accuracy in future models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Models - `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 1 - Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:31:44.303791Z",
     "start_time": "2022-04-21T15:31:44.292625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default arguments - max iterations set to 100\n",
    "logreg_model_simple = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:31:52.475629Z",
     "start_time": "2022-04-21T15:31:48.807873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7270968390371375"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_simple.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_simple.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First simple model is giving us an accuracy rate of **~72.71%** - and a `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Model 1.1 - increasing `max_iter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:33:36.676630Z",
     "start_time": "2022-04-21T15:33:36.660641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Increasing `max_iter` to 1000\n",
    "logreg_model_more_iter = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138,\n",
    "                                  max_iter = 1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:33:52.159557Z",
     "start_time": "2022-04-21T15:33:40.124414Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7271722197095332"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_more_iter.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_more_iter.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Increasing `max_iter` from 100 to 1,000 solved the `ConvergenceWarning`; it also resulted in a *slightly* higher accuracy score: **~72.72%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 2 - new solver (`saga`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:33:57.582513Z",
     "start_time": "2022-04-21T15:33:57.573534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adjusting solver - changed from 'lbfgs' to 'saga'\n",
    "# also dropping `max_iter` back down to default\n",
    "logreg_model_saga = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138,\n",
    "                                  solver = 'saga'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:34:12.957153Z",
     "start_time": "2022-04-21T15:34:02.356786Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.727021458364742"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_saga.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_saga.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ever-so-slightly worse accuracy score (**~72.70%**) when the solver was changed from `lbfgs` to `saga`. But *still* getting that `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 3 - `elasticnet` penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:34:16.688008Z",
     "start_time": "2022-04-21T15:34:16.673819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changed penalty to 'elasticnet', set 'l1_ratio' to 0.6\n",
    "# Reduced max_iter to 10 -  not much sacrifice in accuracy,\n",
    "# better processing time w/ ensemble methods\n",
    "logreg_model_saga_elasnet = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(penalty = 'elasticnet',\n",
    "                                  l1_ratio = 0.6,\n",
    "                                  solver = 'saga',\n",
    "                                  random_state = 138,\n",
    "                                  max_iter = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:34:23.821544Z",
     "start_time": "2022-04-21T15:34:21.567711Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7217699381878486"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_saga_elasnet.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_saga_elasnet.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~72.70%** - these scores aren't moving very much with manual tuning.\n",
    "\n",
    "> Note: When we reduce `max_iter` to 10, our accuracy only drops to **~72.18%**. I will use this in the `StackingClassifier` later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Simple Model 4 - Reduced regularization (`C`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try tuning *one* more hyperparameter in the `LogisticRegression` class before moving on to something else. We'll also drop `max_iter` back down to the default 100 to reduce the amount of processing time needed in future calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:34:28.125863Z",
     "start_time": "2022-04-21T15:34:28.112592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduced regularization by inflating C parameter\n",
    "logreg_less_reg = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(C = 1e5,\n",
    "                                  penalty = 'elasticnet',\n",
    "                                  l1_ratio = 0.6,\n",
    "                                  solver = 'saga',\n",
    "                                  random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:34:49.183174Z",
     "start_time": "2022-04-21T15:34:32.633141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7269712045831449"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_less_reg.fit(X_train, y_train)\n",
    "\n",
    "logreg_less_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No better when the `C` value is set slightly higher, i.e. reduced regularization - **~72.70%**.\n",
    "\n",
    "We're capping out at around **~72.72% accuracy** with various logistic regression models using this set of features. We're also still getting the `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a different algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:36:32.588316Z",
     "start_time": "2022-04-21T15:36:32.572326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple RFC - minimal changes from default hyperparams\n",
    "# Starting small w/ max_depth = 10\n",
    "rfc_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_depth = 10,\n",
    "                                   random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:36:39.165792Z",
     "start_time": "2022-04-21T15:36:35.391291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623498668274787"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "rfc_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Accuracy score on the RFC model with default parameters is around **76.23%**, already nearly a 3.5% increase from our best logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC Model 2 - `max_features` to `sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:36:42.123812Z",
     "start_time": "2022-04-21T15:36:42.106028Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_pipe_two = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_features = 'sqrt',\n",
    "                                   max_depth = 10,\n",
    "                                   random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:36:49.544129Z",
     "start_time": "2022-04-21T15:36:44.877089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623498668274787"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe_two.fit(X_train, y_train)\n",
    "\n",
    "rfc_pipe_two.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Identical accuracy score (76.23%) to our first RFC model, even after modifying `max_features` hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC Model 3 - slight increase to `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:37:49.957476Z",
     "start_time": "2022-04-21T15:37:49.933173Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_pipe_three = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_features = 'sqrt',\n",
    "                                   max_depth = 15,\n",
    "                                   random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:37:58.311776Z",
     "start_time": "2022-04-21T15:37:53.038953Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428312980551786"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe_three.fit(X_train, y_train)\n",
    "\n",
    "rfc_pipe_three.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing `max_depth` by 50% resulted in an ~8% increase in our accuracy score. It's possible that we're overfitting here, but an ensembled method with other algorithms might be able to blunt that overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out a `StackingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:07:39.973717Z",
     "start_time": "2022-04-21T14:07:39.961315Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('logreg_model', logreg_model_saga_elasnet),\n",
    "    ('rfc_model', rfc_model_pipe)\n",
    "]\n",
    "\n",
    "sc_model_pipe = StackingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:08:11.906684Z",
     "start_time": "2022-04-21T14:07:42.508868Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7882556912407659"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "sc_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third logistic regression model - `logreg_model_saga_elasnet` - and our default RFC model - `rfc_model_pipe` - yielded an accuracy rate of **~78.83%** when stacked, our best so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:28:37.500016Z",
     "start_time": "2022-04-21T14:26:48.823453Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.77273869, 0.77035176, 0.76645729, 0.76027139, 0.77069984])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sc_model_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ExtraTreesClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:15:56.829586Z",
     "start_time": "2022-04-21T15:15:56.821599Z"
    }
   },
   "source": [
    "#### Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:11:07.452192Z",
     "start_time": "2022-04-21T14:11:07.433281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default hyperparameters\n",
    "extra_trees_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('etc', ExtraTreesClassifier(random_state=138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:11:33.371812Z",
     "start_time": "2022-04-21T14:11:25.575556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994245942007136"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_pipe.fit(X_train, y_train)\n",
    "\n",
    "extra_trees_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likely way overfit. Let's tune those hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearching the `ExtraTreesClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:40:16.271558Z",
     "start_time": "2022-04-21T14:40:16.264044Z"
    }
   },
   "outputs": [],
   "source": [
    "# New ETC classifier for gridsearching\n",
    "etc_pipe_gs = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('etc', ExtraTreesClassifier(random_state=138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T14:59:22.035144Z",
     "start_time": "2022-04-21T14:59:22.017176Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters = {'etc__criterion': ['gini', 'entropy'],\n",
    "              'etc__min_samples_leaf': [1, 5, 10],\n",
    "              'etc__max_depth': [5, 10, 20, 30]}\n",
    "\n",
    "gs_etc = GridSearchCV(estimator=etc_pipe_gs,\n",
    "                      param_grid=parameters,\n",
    "                      cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:09:27.616879Z",
     "start_time": "2022-04-21T14:59:24.559422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['amount_tsh',\n",
       "                                                                          'gps_height',\n",
       "                                                                          'population']),\n",
       "                                                                        ('subpipe_year',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(missing_values=0,\n",
       "                                                                                                        strategy='median')),...\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         ['basin',\n",
       "                                                                          'region',\n",
       "                                                                          'payment_type',\n",
       "                                                                          'quantity',\n",
       "                                                                          'quality_group',\n",
       "                                                                          'permit',\n",
       "                                                                          'public_meeting',\n",
       "                                                                          'extraction_type_class',\n",
       "                                                                          'source_type',\n",
       "                                                                          'source_class',\n",
       "                                                                          'waterpoint_type'])])),\n",
       "                                       ('etc',\n",
       "                                        ExtraTreesClassifier(max_depth=10,\n",
       "                                                             random_state=138))]),\n",
       "             param_grid={'etc__criterion': ['gini', 'entropy'],\n",
       "                         'etc__max_depth': [5, 10, 20, 30],\n",
       "                         'etc__min_samples_leaf': [1, 5, 10]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:09:31.734464Z",
     "start_time": "2022-04-21T15:09:31.721500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'etc__criterion': 'gini', 'etc__max_depth': 20, 'etc__min_samples_leaf': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_etc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:09:35.865569Z",
     "start_time": "2022-04-21T15:09:35.853549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891853917154563"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_etc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:09:42.173798Z",
     "start_time": "2022-04-21T15:09:42.157969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modifying the pipeline and classifier to match\n",
    "# best parameters found in gridsearch\n",
    "\n",
    "etc_pipe_gs = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('etc', ExtraTreesClassifier(max_depth = 20,\n",
    "                                 random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:09:59.059410Z",
     "start_time": "2022-04-21T15:09:45.964500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021307603397155"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc_pipe_gs.fit(X_train, y_train)\n",
    "\n",
    "etc_pipe_gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, it looks like we're probably still overfitting with the `ExtraTreesClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:14:01.760263Z",
     "start_time": "2022-04-21T15:14:01.746298Z"
    }
   },
   "outputs": [],
   "source": [
    "gbc_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('gbc', GradientBoostingClassifier(random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:15:52.305878Z",
     "start_time": "2022-04-21T15:14:40.797582Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537564701743806"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "gbc_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `XGBoost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give this a swing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:17:57.202974Z",
     "start_time": "2022-04-21T15:17:57.197022Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('xgb', XGBClassifier(random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T15:18:40.424623Z",
     "start_time": "2022-04-21T15:18:18.830275Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350419619076336"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dummy` - 0.54209\n",
    "- `lr` (best) - 0.72717\n",
    "- `rfc` (best) - 0.84283\n",
    "- `etc` (best) - 0.90123\n",
    "- `gbc` - 0.75375\n",
    "- `xgb` - 0.83504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:30:55.465475Z",
     "start_time": "2022-04-21T16:30:55.459524Z"
    }
   },
   "outputs": [],
   "source": [
    "final_estimators = [\n",
    "    ('rfc_model', rfc_pipe_three),\n",
    "    ('xgb_model', xgb_model_pipe)\n",
    "]\n",
    "\n",
    "final_model_pipe = StackingClassifier(final_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:32:43.744088Z",
     "start_time": "2022-04-21T16:30:59.328487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rfc_model',\n",
       "                                Pipeline(steps=[('ct',\n",
       "                                                 ColumnTransformer(remainder='passthrough',\n",
       "                                                                   transformers=[('subpipe_num',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                                                  ('ss',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  ['amount_tsh',\n",
       "                                                                                   'gps_height',\n",
       "                                                                                   'population']),\n",
       "                                                                                 ('subpipe_year',\n",
       "                                                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                                                   SimpleImputer(missing_values=0,\n",
       "                                                                                                                 stra...\n",
       "                                                               interaction_constraints='',\n",
       "                                                               learning_rate=0.300000012,\n",
       "                                                               max_delta_step=0,\n",
       "                                                               max_depth=6,\n",
       "                                                               min_child_weight=1,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints='()',\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=0,\n",
       "                                                               num_parallel_tree=1,\n",
       "                                                               objective='multi:softprob',\n",
       "                                                               random_state=138,\n",
       "                                                               reg_alpha=0,\n",
       "                                                               reg_lambda=1,\n",
       "                                                               scale_pos_weight=None,\n",
       "                                                               subsample=1,\n",
       "                                                               tree_method='exact',\n",
       "                                                               validate_parameters=1,\n",
       "                                                               verbosity=None))]))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:32:57.643553Z",
     "start_time": "2022-04-21T16:32:56.094164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526810392482034"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_pipe.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:36:10.456840Z",
     "start_time": "2022-04-21T16:36:08.960385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573048941239463"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true = y_train,\n",
    "                y_pred = final_model_pipe.predict(X_train),\n",
    "                average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:36:32.836829Z",
     "start_time": "2022-04-21T16:36:31.276936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526810392482034"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true = y_train,\n",
    "             y_pred = final_model_pipe.predict(X_train),\n",
    "             average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen data (`test` sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:33:02.039972Z",
     "start_time": "2022-04-21T16:33:01.364270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932863993470054"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:38:16.089181Z",
     "start_time": "2022-04-21T16:38:15.275671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907154295237442"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true = y_test,\n",
    "                y_pred = final_model_pipe.predict(X_test),\n",
    "                average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T16:38:20.507354Z",
     "start_time": "2022-04-21T16:38:19.695281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932863993470054"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true = y_test,\n",
    "             y_pred = final_model_pipe.predict(X_test),\n",
    "             average = 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
