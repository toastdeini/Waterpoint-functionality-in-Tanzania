{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Scratchwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:42.753759Z",
     "start_time": "2022-04-21T03:32:42.740769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Packages for data cleaning, plotting, and manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# scikit-learn libraries/functions/classes\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "                             StackingClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:43.778917Z",
     "start_time": "2022-04-21T03:32:43.765706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shows *all* columns in dataframe, i.e. does not truncate horizontally;\n",
    "# feel free to comment out if undesired\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:45.126826Z",
     "start_time": "2022-04-21T03:32:44.751728Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing training data\n",
    "train_val = pd.read_csv('../data/training_set_values.csv')\n",
    "\n",
    "# Only using `status_group` column from label set, to\n",
    "# avoid duplicating `id` column\n",
    "train_label = pd.read_csv('../data/training_set_labels.csv',\n",
    "                             usecols = ['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:46.110553Z",
     "start_time": "2022-04-21T03:32:46.065242Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenating separate .csv files\n",
    "df = pd.concat(objs = [train_val, train_label],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:47.154546Z",
     "start_time": "2022-04-21T03:32:47.141836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns determined to be either irrelevant or\n",
    "# superfluous in exploratory analysis\n",
    "\n",
    "cols_to_drop = [\n",
    "    'id',  # unique identifier, not useful for modeling\n",
    "    'date_recorded',  # superfluous information, too many unique records\n",
    "    'recorded_by',  # no unique information + no unique values across 59.4k rows\n",
    "    'funder',   \n",
    "    'installer',  # large number of unique values (see also `funder`);\n",
    "                  # may be added back in later\n",
    "    'wpt_name',  # identifier column, not useful for modeling\n",
    "    'num_private',  # data dict. does not provide details for this column\n",
    "    'subvillage',  # too many unique values - uninformative for modeling\n",
    "    'region_code',  # redundant information vis-a-visa the simpler `region`\n",
    "    'district_code',  # may be added back in later\n",
    "    'lga',\n",
    "    'ward',  # redundant location data (with `lga`)\n",
    "    'scheme_management',  # may be added back in later\n",
    "    'scheme_name',  # large number of nulls, redundant vis-a-vis `scheme_management`\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',  # using `extraction_type_class` for generalized info\n",
    "    'management',\n",
    "    'management_group',  # may be added back in later\n",
    "    'payment',  # identical information to `payment_type`\n",
    "    'water_quality',  # comparable information to `quality_group` - redundant\n",
    "    'quantity_group',  # identical information to `quantity` - redundant\n",
    "    'source',  # redundant with other `source_` columns\n",
    "    'waterpoint_type_group'  # used `waterpoint_type` instead\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:48.154634Z",
     "start_time": "2022-04-21T03:32:48.097074Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = cols_to_drop).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary modifications for modeling, to be written into pipelines:\n",
    "\n",
    "- One-hot encoding:\n",
    "    - `basin`\n",
    "    - `extraction_type_class`\n",
    "    - `payment_type`\n",
    "    - `permit`\n",
    "    - `public_meeting`\n",
    "    - `quality_group`\n",
    "    - `quantity`\n",
    "    - `region`\n",
    "    - `source_type`\n",
    "    - `source_class`\n",
    "    - `waterpoint_type`\n",
    "- Numerical scaling:\n",
    "    - `population` - (impute zeroes with median?)\n",
    "    - `gps_height` - impute zeroes with median\n",
    "    - `latitude` / `longitude` - impute zeroes with mean\n",
    "    - `construction_year` - use KNN imputing\n",
    "    \n",
    "Our target variable, `status_group`, will also be **label encoded** for readability and consistency:\n",
    "- `0` = 'functional'\n",
    "- `1` = 'non functional'\n",
    "- `2` = 'functional needs repair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:49.168342Z",
     "start_time": "2022-04-21T03:32:49.154876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subpipes for imputing median values - to be used for `latitude` and `longitude`\n",
    "subpipe_lat      = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = -2.000000e-08,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "subpipe_long     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0.000000,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "\n",
    "# Subpipe for imputing median values\n",
    "subpipe_num      = Pipeline(steps=[('num_impute', SimpleImputer(strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for `construction_year`\n",
    "subpipe_year     = Pipeline(steps=[('num_impute', SimpleImputer(missing_values = 0,\n",
    "                                                                strategy = 'median')),\n",
    "                                   ('ss', StandardScaler())])\n",
    "\n",
    "# Subpipe for categorical features including `basin`, `payment_type`\n",
    "subpipe_cat      = Pipeline(steps=[('freq_imputer_nan', SimpleImputer(strategy = 'most_frequent')),\n",
    "                                   ('freq_imputer_unk', SimpleImputer(strategy = 'most_frequent',\n",
    "                                                                      missing_values = 'unknown')),\n",
    "                                   ('ohe', OneHotEncoder(drop = 'if_binary',\n",
    "                                                         sparse = False,\n",
    "                                                         handle_unknown = 'ignore'))])\n",
    "\n",
    "\n",
    "# Subpipe for the target column, `status_group`\n",
    "subpipe_label    = Pipeline(steps=[('le', LabelEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:50.162976Z",
     "start_time": "2022-04-21T03:32:50.148835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to be passed through numerical pipeline\n",
    "num_cols = ['amount_tsh',\n",
    "            'gps_height',\n",
    "            'population']\n",
    "\n",
    "# Columns to be passed through categorical pipeline\n",
    "cat_cols = ['basin',\n",
    "            'region',\n",
    "            'payment_type',\n",
    "            'quantity',\n",
    "            'quality_group',\n",
    "            'permit',\n",
    "            'public_meeting',\n",
    "            'extraction_type_class',\n",
    "            'source_type',\n",
    "            'source_class',\n",
    "            'waterpoint_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:51.120478Z",
     "start_time": "2022-04-21T03:32:51.106389Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num', subpipe_num, num_cols),\n",
    "    ('subpipe_year', subpipe_year, ['construction_year']),\n",
    "    ('subpipe_long', subpipe_long, ['longitude']),\n",
    "    ('subpipe_lat', subpipe_lat, ['latitude']),\n",
    "    ('subpipe_cat', subpipe_cat, cat_cols)],\n",
    "                       remainder = 'passthrough')\n",
    "\n",
    "# ('subpipe_label', subpipe_label, ['status_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split and Initial Preparation for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:52.245201Z",
     "start_time": "2022-04-21T03:32:52.231399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting DataFrame into features/values DataFrame\n",
    "# (i.e. `X`) and labels series (`y`)\n",
    "\n",
    "X = df.drop('status_group', axis = 1)\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:32:53.316675Z",
     "start_time": "2022-04-21T03:32:53.287257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting internal training data into separate\n",
    "# training and test sets for (eventual) internal validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 138)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:00.969617Z",
     "start_time": "2022-04-21T03:33:00.961080Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('dummy', DummyClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:02.685494Z",
     "start_time": "2022-04-21T03:33:02.159256Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420875420875421"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "dummy_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Score on training data\n",
    "dummy_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn's `DummyClassifier` predicts on the training data with an accuracy score of ~0.542, equal to the proportion of the **most frequent class** (`functional`). This is because, as a dummy model, it predicts `functional` (the most frequent value) every time.\n",
    "\n",
    "We'll be looking to improve on that 54.2% accuracy in future models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Models - `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 1 - Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:07.765080Z",
     "start_time": "2022-04-21T03:33:07.751118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default arguments - max iterations set to 100\n",
    "logreg_model_simple = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:11.346121Z",
     "start_time": "2022-04-21T03:33:08.807707Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7270968390371375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_simple.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_simple.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First simple model is giving us an accuracy rate of **~72.71%** - and a `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Model 1.1 - increasing `max_iter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:12.366740Z",
     "start_time": "2022-04-21T03:33:12.353126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Increasing `max_iter` to 1000\n",
    "logreg_model_more_iter = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138,\n",
    "                                  max_iter = 1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:21.114577Z",
     "start_time": "2022-04-21T03:33:13.374008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7271722197095332"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_more_iter.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_more_iter.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Increasing `max_iter` from 100 to 1,000 solved the `ConvergenceWarning`; it also resulted in a *slightly* higher accuracy score: **~72.72%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 2 - new solver (`saga`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:22.219545Z",
     "start_time": "2022-04-21T03:33:22.206707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adjusting solver - changed from 'lbfgs' to 'saga'\n",
    "# also dropping `max_iter` back down to default\n",
    "logreg_model_saga = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(random_state = 138,\n",
    "                                  solver = 'saga'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:32.084526Z",
     "start_time": "2022-04-21T03:33:23.162854Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.727021458364742"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_saga.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_saga.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ever-so-slightly worse accuracy score (**~72.70%**) when the solver was changed from `lbfgs` to `saga`. But *still* getting that `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model 3 - `elasticnet` penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:33.311353Z",
     "start_time": "2022-04-21T03:33:33.299024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changed penalty to 'elasticnet', set 'l1_ratio' to 0.6\n",
    "# Reduced max_iter to 10 -  not much sacrifice in accuracy,\n",
    "# better processing time w/ ensemble methods\n",
    "logreg_model_saga_elasnet = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(penalty = 'elasticnet',\n",
    "                                  l1_ratio = 0.6,\n",
    "                                  solver = 'saga',\n",
    "                                  random_state = 138,\n",
    "                                  max_iter = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:36.354304Z",
     "start_time": "2022-04-21T03:33:34.580685Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7217699381878486"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_saga_elasnet.fit(X_train, y_train)\n",
    "\n",
    "logreg_model_saga_elasnet.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~72.70%** - these scores aren't moving very much with manual tuning.\n",
    "\n",
    "> Note: When we reduce `max_iter` to 10, our accuracy only drops to **~72.18%**. I will use this in the `StackingClassifier` later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Simple Model 4 - Reduced regularization (`C`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try tuning *one* more hyperparameter in the `LogisticRegression` class before moving on to something else. We'll also drop `max_iter` back down to the default 100 to reduce the amount of processing time needed in future calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:37.469309Z",
     "start_time": "2022-04-21T03:33:37.456098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduced regularization by inflating C parameter\n",
    "logreg_less_reg = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('logreg', LogisticRegression(C = 1e5,\n",
    "                                  penalty = 'elasticnet',\n",
    "                                  l1_ratio = 0.6,\n",
    "                                  solver = 'saga',\n",
    "                                  random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:51.169473Z",
     "start_time": "2022-04-21T03:33:38.656517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7269712045831449"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_less_reg.fit(X_train, y_train)\n",
    "\n",
    "logreg_less_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No better when the `C` value is set slightly higher, i.e. reduced regularization - **~72.70%**.\n",
    "\n",
    "We're capping out at around **~72.72% accuracy** with various logistic regression models using this set of features. We're also still getting the `ConvergenceWarning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:52.805858Z",
     "start_time": "2022-04-21T03:33:52.792843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple RFC - minimal changes from default hyperparams\n",
    "# Starting small w/ max_depth = 10\n",
    "rfc_model_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_depth = 10,\n",
    "                                   random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:33:59.139967Z",
     "start_time": "2022-04-21T03:33:54.227423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623498668274787"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "rfc_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Accuracy score on the RFC model with default parameters is around **76.23%**, already nearly a 3.5% increase from our best logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC Model 2 - `max_features` to `sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:34:00.285208Z",
     "start_time": "2022-04-21T03:34:00.272240Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_pipe_two = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('rfc', RandomForestClassifier(max_features = 'sqrt',\n",
    "                                   max_depth = 10,\n",
    "                                   random_state = 138))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:34:06.122450Z",
     "start_time": "2022-04-21T03:34:01.562391Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623498668274787"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe_two.fit(X_train, y_train)\n",
    "\n",
    "rfc_pipe_two.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Identical accuracy score (76.23%) to our first RFC model, even after modifying `max_features` hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `StackingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:34:07.297921Z",
     "start_time": "2022-04-21T03:34:07.283416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('logreg_model', logreg_model_saga_elasnet),\n",
    "    ('rfc_model', rfc_pipe_two)\n",
    "]\n",
    "\n",
    "sc_model_pipe = StackingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T03:34:39.025874Z",
     "start_time": "2022-04-21T03:34:08.512586Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\toast\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7882556912407659"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "sc_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third logistic regression model - `logreg_model_saga_elasnet` - and our second RFC model - `rfc_pipe_two` - yielded an accuracy rate of **~78.83%** when stacked, our best so far.\n",
    "\n",
    "It also took **two minutes** to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ExtraTreesClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
